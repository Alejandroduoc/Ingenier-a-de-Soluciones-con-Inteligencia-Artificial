# EVALUACIONES

## EVALUACIÓN FINAL TRANSVERSAL

**Tipo de Evaluación:** Evaluación Final Transversal  
**Resultados de Aprendizaje:** RA1, RA2, RA3  
**Indicadores de Logro:** IL1.3, IL1.4, IL2.3, IL2.4, IL3.3, IL3.4  
**Situación Evaluativa:** Entrega de encargo con presentación  
**Agente Evaluativo:** Heteroevaluación (Docente)  
**Tipo de Trabajo:** Parejas  
**Ponderación:** 40% (30% - 70%)  
**Ambiente de Aprendizaje:** Taller de Proyectos (Taite 7)  
**N° Estudiantes:** 30  
**Horas Docencia Directa:** 4 hrs  
**Horas Trabajo Autónomo:** 4 hrs  

**Descripción Evaluación Dirigida al Docente:**
La Evaluación Final Transversal corresponde a la versión final del proyecto desarrollado en parejas a lo largo del semestre, y su presentación evaluada de manera individual.

A partir de documentación específica entregada por el/la docente, los/las estudiantes elaboran un informe escrito en el cual diseñan, implementan y evalúan una solución completa basada en agentes de IA para un caso organizacional real. Justifican sus decisiones de diseño, documentan la arquitectura, implementan protocolos de seguridad y proponen mejoras basadas en métricas de observabilidad.

**Actividades Trabajo Autónomo:**
- Investigación de caso, diseño de arquitectura, implementación de prototipo, análisis de métricas, preparación de presentación
- Estudio personal de documentación técnica sobre frameworks de agentes de IA
- Recopilación de información sobre casos de uso organizacionales
- Investigación de mejores prácticas en seguridad y ética para sistemas de IA
- Revisión de métricas de observabilidad y evaluación de agentes

---

## EVALUACIÓN FORMATIVA 1 - TÉCNICAS DE PROMPT ENGINEERING

**Tipo de Evaluación:** Evaluación Formativa 1  
**Resultados de Aprendizaje:** RA1  
**Indicadores de Logro:** IL1.1, IL1.2, IL1.3, IL1.4  
**Situación Evaluativa:** Prueba de selección única  
**Agente Evaluativo:** Heteroevaluación (Docente)  
**Tipo de Trabajo:** Individual  
**Ponderación:** No aplica  
**Ambiente de Aprendizaje:** Taller de Proyectos (Taite 7)  
**N° Estudiantes:** 30  
**Horas Docencia Directa:** 2 hrs  
**Horas Trabajo Autónomo:** 2 hrs  

**Descripción Evaluación Dirigida al Docente:**
La Evaluación Formativa 1 corresponde a una prueba de selección única o quiz realizado en AVA de 8 preguntas sobre conceptos fundamentales de agentes de IA. Las preguntas evalúan conocimientos teóricos sobre arquitectura de agentes LLM, frameworks, tipos de memoria, function calling, integración con herramientas externas y estrategias de planificación.

**Actividades Trabajo Autónomo:**
- Estudio personal de documentación oficial sobre técnicas de prompt engineering (zero-shot, few-shot, chain-of-thought)
- Recopilación de ejemplos de prompts efectivos para diferentes tipos de tareas
- Investigación de patrones de redacción de prompts en repositorios especializados y documentación de APIs de modelos de lenguaje

---

## EVALUACIÓN PARCIAL 1 - DISEÑO DE SOLUCIÓN CON LLM Y RAG

**Tipo de Evaluación:** Evaluación Parcial 1  
**Resultados de Aprendizaje:** RA1  
**Indicadores de Logro:** IL1.1, IL1.2, IL1.3, IL1.4  
**Situación Evaluativa:** Presentación  
**Agente Evaluativo:** Heteroevaluación (Docente)  
**Tipo de Trabajo:** Parejas  
**Ponderación:** 30%  
**Ambiente de Aprendizaje:** Taller de Proyectos (Taite 7)  
**N° Estudiantes:** 30  
**Horas Docencia Directa:** 2 hrs  
**Horas Trabajo Autónomo:** 2 hrs  

**Descripción Evaluación Dirigida al Docente:**
Los estudiantes deben desarrollar un proyecto integral que corresponde a una presentación en parejas, donde incluyen:

1. Análisis del caso organizacional asignado identificando requerimientos específicos
2. Formulación de prompts optimizados para el contexto del caso (IL1.1)
3. Diseño e implementación de un pipeline RAG que combine fuentes de datos internas y externas del caso (IL1.2)
4. Construcción de una arquitectura de solución que integre LLMs con herramientas de recuperación de información (IL1.3)
5. Documentación técnica justificando las decisiones de diseño

**Actividades Trabajo Autónomo:**
- Estudio personal de documentación técnica sobre arquitecturas RAG y pipelines de embeddings
- Recopilación de información sobre el sector organizacional del caso asignado para comprender el contexto de negocio
- Investigación de técnicas de chunking y selección de ventanas contextuales en bases de datos vectoriales
- Revisión de bibliografía sobre evaluación de precisión y relevancia en sistemas de recuperación de información

---

## EVALUACIÓN FORMATIVA 2 - DISEÑO DE AGENTES

**Tipo de Evaluación:** Evaluación Formativa 2  
**Resultados de Aprendizaje:** RA2  
**Indicadores de Logro:** IL2.1, IL2.2  
**Situación Evaluativa:** Prueba de selección única  
**Agente Evaluativo:** Heteroevaluación (Docente)  
**Tipo de Trabajo:** Individual  
**Ponderación:** No aplica  
**Ambiente de Aprendizaje:** Taller de Proyectos (Taite 7)  
**N° Estudiantes:** 30  
**Horas Docencia Directa:** 2 hrs  
**Horas Trabajo Autónomo:** 2 hrs  

**Descripción Evaluación Dirigida al Docente:**
La Evaluación Formativa 2 corresponde a una prueba de selección única o quiz realizado en AVA de 8 preguntas sobre conceptos fundamentales de agentes de IA.

Las preguntas evaluarán conocimientos teóricos sobre arquitectura de agentes LLM, frameworks para agentes, Agentic RAG, MCP, tipos de memoria (short-term, long-term), function calling, integración con herramientas externas y estrategias de planificación.

**CRITERIOS DE EVALUACIÓN:** Comprensión de conceptos de autonomía y razonamiento en agentes (IL2.1), conocimiento sobre configuración de procesos de memoria y recuperación de contexto (IL2.2).

**Actividades Trabajo Autónomo:**
- Estudio personal de material teórico sobre paradigmas de agentes inteligentes y arquitecturas LLM
- Revisión de documentación sobre frameworks de agentes y tipos de memoria
- Investigación de conceptos sobre function calling, Agentic RAG, MCP y herramientas externas

---

## EVALUACIÓN PARCIAL 2 - DESARROLLO DE AGENTE FUNCIONAL

**Tipo de Evaluación:** Evaluación Parcial 2  
**Resultados de Aprendizaje:** RA2  
**Indicadores de Logro:** IL2.1, IL2.2, IL2.3, IL2.4  
**Situación Evaluativa:** Encargo sin presentación  
**Agente Evaluativo:** Heteroevaluación (Docente)  
**Tipo de Trabajo:** Parejas  
**Ponderación:** 35%  
**Ambiente de Aprendizaje:** Taller de Proyectos (Taite 7)  
**N° Estudiantes:** 30  
**Horas Docencia Directa:** 2 hrs  
**Horas Trabajo Autónomo:** 2 hrs  

**Descripción Evaluación Dirigida al Docente:**
Los estudiantes deben desarrollar un proyecto integral que corresponde a la construcción de un repositorio de código en gitbug, en el cual incluyen:

1. Análisis del flujo de trabajo organizacional asignado identificando tareas cognitivas complejas a automatizar
2. Construcción de un agente funcional que integre herramientas de consulta, escritura y razonamiento usando frameworks específicos (IL2.1)
3. Configuración de procesos de memoria (short-term y long-term) y recuperación de contexto para asegurar continuidad en tareas prolongadas (IL2.2)
4. Implementación de estrategias de planificación y toma de decisiones que permitan al agente ajustar su comportamiento ante múltiples etapas y condiciones cambiantes (IL2.3)
5. Documentación técnica (README.md) completa del diseño e implementación explicando la orquestación entre componentes y su relación con el flujo automatizado (IL2.4)

**Actividades Trabajo Autónomo:**
- Estudio personal de documentación técnica sobre frameworks de agentes y arquitecturas de memoria
- Recopilación de información sobre el proceso organizacional asignado para comprender el contexto y requerimientos del flujo de trabajo
- Investigación de estrategias de planificación y toma de decisiones en sistemas multi-agente
- Revisión de estándares de documentación técnica para arquitecturas de software y diagramación de componentes

---

## EVALUACIÓN FORMATIVA 3 - OBSERVABILIDAD Y TRAZABILIDAD

**Tipo de Evaluación:** Evaluación Formativa 3  
**Resultados de Aprendizaje:** RA3  
**Indicadores de Logro:** IL3.1, IL3.2  
**Situación Evaluativa:** Prueba de selección única  
**Agente Evaluativo:** Heteroevaluación (Docente)  
**Tipo de Trabajo:** Individual  
**Ponderación:** No aplica  
**Ambiente de Aprendizaje:** Taller de Proyectos (Taite 7)  
**N° Estudiantes:** 30  
**Horas Docencia Directa:** 2 hrs  
**Horas Trabajo Autónomo:** 2 hrs  

**Descripción Evaluación Dirigida al Docente:**
La Evaluación Formativa 3 corresponde a una prueba de selección única o quiz realizado en AVA de 8 preguntas sobre conceptos fundamentales de observabilidad y trazabilidad en agentes de IA. Las preguntas evaluarán conocimientos teóricos sobre métricas de observabilidad (latencia, frecuencia de errores, uso de tokens), herramientas de monitoreo, análisis de logs de conversación, rutas de ejecución y técnicas de identificación de puntos de falla.

**CRITERIOS DE EVALUACIÓN:** Comprensión de métricas para medir precisión, latencia y consistencia de agentes en escenarios variables (IL3.1), conocimiento sobre análisis de registros de ejecución y herramientas de trazabilidad para identificar puntos de falla (IL3.2).

**Actividades Trabajo Autónomo:**
- Estudio personal de material teórico sobre métricas de observabilidad y herramientas de monitoreo de agentes
- Revisión de documentación sobre análisis de logs y trazabilidad en sistemas de IA
- Investigación de conceptos sobre latencia, frecuencia de errores y uso de tokens en agentes LLM

---

## EVALUACIÓN PARCIAL 3 - EVALUACIÓN DE DESEMPEÑO DE AGENTES

**Tipo de Evaluación:** Evaluación Parcial 3  
**Resultados de Aprendizaje:** RA3  
**Indicadores de Logro:** IL3.1, IL3.2, IL3.3, IL3.4  
**Situación Evaluativa:** Encargo sin presentación  
**Agente Evaluativo:** Heteroevaluación (Docente)  
**Tipo de Trabajo:** Parejas  
**Ponderación:** 35%  
**Ambiente de Aprendizaje:** Taller de Proyectos (Taite 7)  
**N° Estudiantes:** 30  
**Horas Docencia Directa:** 2 hrs  
**Horas Trabajo Autónomo:** 2 hrs  

**Descripción Evaluación Dirigida al Docente:**
Los estudiantes deben implementar herramientas de observabilidad para un agente existente y analizar los registros de ejecución para identificar puntos de mejora. Para ello entregan lo desarrollado a través de un enlace a un dashboard de métricas.

Se evaluará la aplicación correcta de métricas de observabilidad para medir precisión, latencia y consistencia del agente en escenarios con variabilidad de datos (IL3.1), y la capacidad de analizar registros de ejecución utilizando herramientas de trazabilidad para identificar efectivamente puntos de falla o mejora en flujos automatizados (IL3.2). La selección apropiada de métricas, la implementación técnica de herramientas de monitoreo y la calidad del análisis de registros serán los aspectos centrales de evaluación.

**Actividades Trabajo Autónomo:**
- Estudio personal de documentación técnica sobre implementación de herramientas de observabilidad y monitoreo
- Recopilación de información sobre mejores prácticas en análisis de logs y registros de ejecución de agentes
- Investigación de herramientas específicas de trazabilidad y técnicas de identificación de puntos de falla en sistemas automatizados
- Revisión de casos de estudio sobre optimización de agentes basada en métricas observadas