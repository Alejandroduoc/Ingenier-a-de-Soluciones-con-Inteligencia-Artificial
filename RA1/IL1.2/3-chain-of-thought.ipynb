{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Chain-of-Thought (CoT) Prompting - Razonamiento Paso a Paso\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender el concepto de Chain-of-Thought (CoT) prompting\n",
    "- Implementar CoT con y sin ejemplos\n",
    "- Aplicar CoT a problemas complejos y razonamiento lógico\n",
    "- Combinar CoT con otras técnicas de prompting\n",
    "\n",
    "## ¿Qué es Chain-of-Thought?\n",
    "\n",
    "Chain-of-Thought (CoT) es una técnica que hace que el modelo \"**piense en voz alta**\" mostrando su proceso de razonamiento paso a paso antes de llegar a la respuesta final.\n",
    "\n",
    "### Principio Básico:\n",
    "En lugar de saltar directamente a la respuesta, el modelo:\n",
    "1. **Descompone** el problema en pasos\n",
    "2. **Razona** cada paso explícitamente  \n",
    "3. **Construye** hacia la solución final\n",
    "4. **Proporciona** la respuesta con justificación\n",
    "\n",
    "### Ventajas:\n",
    "- **Mejor precisión**: Especialmente en problemas complejos\n",
    "- **Transparencia**: Puedes ver el razonamiento\n",
    "- **Debugging**: Identificar dónde falla el razonamiento\n",
    "- **Confianza**: Mayor seguridad en la respuesta\n",
    "\n",
    "### Casos de Uso Ideales:\n",
    "- Problemas matemáticos\n",
    "- Razonamiento lógico\n",
    "- Análisis complejos\n",
    "- Toma de decisiones\n",
    "- Resolución de problemas multi-paso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo configurado para Chain-of-Thought\n",
      "✓ Temperature baja para razonamiento consistente\n"
     ]
    }
   ],
   "source": [
    "# Configuración inicial\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "import time\n",
    "\n",
    "# Configurar el modelo\n",
    "llm = ChatOpenAI(\n",
    "    base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "    api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "    model=\"gpt-4\",\n",
    "    temperature=0.1  # Baja temperatura para razonamiento más consistente\n",
    ")\n",
    "\n",
    "print(\"✓ Modelo configurado para Chain-of-Thought\")\n",
    "print(\"✓ Temperature baja para razonamiento consistente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparación: Sin CoT vs Con CoT\n",
    "\n",
    "Veamos la diferencia dramática que puede hacer CoT en problemas complejos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACIÓN: SIN CoT vs CON CoT ===\n",
      "\n",
      "1. SIN CHAIN-OF-THOUGHT:\n",
      "------------------------------\n",
      "Error: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 22611 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 22611 seconds before retrying.'}}\n",
      "\n",
      "============================================================\n",
      "\n",
      "2. CON CHAIN-OF-THOUGHT:\n",
      "------------------------------\n",
      "Error: Error code: 429 - {'error': {'code': 'RateLimitReached', 'message': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 22609 seconds before retrying.', 'details': 'Rate limit of 50 per 86400s exceeded for UserByModelByDay. Please wait 22609 seconds before retrying.'}}\n",
      "\n",
      "=== ANÁLISIS ===\n",
      "• Sin CoT: Puede llegar a respuesta incorrecta o saltar pasos\n",
      "• Con CoT: Muestra razonamiento completo y reduce errores\n",
      "• CoT especialmente útil para problemas multi-paso\n"
     ]
    }
   ],
   "source": [
    "# Comparación directa: razonamiento directo vs CoT\n",
    "def comparar_sin_vs_con_cot():\n",
    "    print(\"=== COMPARACIÓN: SIN CoT vs CON CoT ===\")\n",
    "    \n",
    "    # Problema complejo que requiere múltiples pasos\n",
    "    problema = \"\"\"Una tienda tiene una promoción: 'Compra 2 productos y obtén 30% de descuento en el más barato'. \n",
    "    Juan compra una camiseta de 45€, unos zapatos de 120€ y una chaqueta de 80€. \n",
    "    ¿Cuánto paga en total?\"\"\"\n",
    "    \n",
    "    # Prompt sin CoT\n",
    "    prompt_sin_cot = f\"\"\"Resuelve este problema:\n",
    "    \n",
    "{problema}\n",
    "    \n",
    "Respuesta:\"\"\"\n",
    "    \n",
    "    # Prompt con CoT\n",
    "    prompt_con_cot = f\"\"\"Resuelve este problema paso a paso:\n",
    "    \n",
    "{problema}\n",
    "    \n",
    "Piensa paso a paso:\n",
    "1. Primero identifica los productos y precios\n",
    "2. Determina cómo se aplica la promoción\n",
    "3. Calcula el descuento\n",
    "4. Calcula el total final\n",
    "    \n",
    "Razonamiento:\"\"\"\n",
    "    \n",
    "    # Probar sin CoT\n",
    "    print(\"\\n1. SIN CHAIN-OF-THOUGHT:\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        response_sin = llm.invoke([HumanMessage(content=prompt_sin_cot)])\n",
    "        print(response_sin.content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    \n",
    "    # Probar con CoT\n",
    "    print(\"\\n2. CON CHAIN-OF-THOUGHT:\")\n",
    "    print(\"-\" * 30)\n",
    "    try:\n",
    "        response_con = llm.invoke([HumanMessage(content=prompt_con_cot)])\n",
    "        print(response_con.content)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\n=== ANÁLISIS ===\")\n",
    "    print(\"• Sin CoT: Puede llegar a respuesta incorrecta o saltar pasos\")\n",
    "    print(\"• Con CoT: Muestra razonamiento completo y reduce errores\")\n",
    "    print(\"• CoT especialmente útil para problemas multi-paso\")\n",
    "\n",
    "# Ejecutar comparación\n",
    "comparar_sin_vs_con_cot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zero-Shot Chain-of-Thought\n",
    "\n",
    "La forma más simple de CoT: simplemente pedirle al modelo que \"piense paso a paso\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Zero-shot CoT: solo agregar \"piensa paso a paso\"\n",
    "def zero_shot_cot():\n",
    "    print(\"=== ZERO-SHOT CHAIN-OF-THOUGHT ===\")\n",
    "    \n",
    "    problemas = [\n",
    "        \"Si un tren viaja a 80 km/h y necesita llegar a una ciudad que está a 240 km, pero se detiene 15 minutos en una estación intermedia, ¿cuánto tiempo total toma el viaje?\",\n",
    "        \"Una empresa tiene 150 empleados. El 40% trabaja en desarrollo, el 25% en ventas, el 20% en marketing y el resto en administración. Si cada empleado de desarrollo gana 50,000€ anuales, ¿cuál es el costo anual solo del departamento de desarrollo?\",\n",
    "        \"María tiene el triple de edad que su hermana Ana. En 5 años, María tendrá el doble de la edad que tendrá Ana. ¿Cuántos años tiene cada una ahora?\"\n",
    "    ]\n",
    "    \n",
    "    for i, problema in enumerate(problemas, 1):\n",
    "        print(f\"\\n{i}. PROBLEMA:\")\n",
    "        print(f\"{problema}\")\n",
    "        \n",
    "        # Prompt zero-shot CoT\n",
    "        prompt = f\"{problema}\\n\\nPiensa paso a paso:\"\n",
    "        \n",
    "        try:\n",
    "            response = llm.invoke([HumanMessage(content=prompt)])\n",
    "            print(\"\\nSOLUCIÓN:\")\n",
    "            print(response.content)\n",
    "            \n",
    "            # Análisis básico del razonamiento\n",
    "            pasos = response.content.count('\\n')\n",
    "            tiene_calculo = any(op in response.content for op in ['+', '-', '*', '/', '=', '%'])\n",
    "            \n",
    "            print(f\"\\nAnálisis: {pasos} líneas de razonamiento, {'con' if tiene_calculo else 'sin'} cálculos explícitos\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "        \n",
    "        print(\"-\" * 80)\n",
    "\n",
    "# Ejecutar zero-shot CoT\n",
    "zero_shot_cot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few-Shot Chain-of-Thought\n",
    "\n",
    "Combinamos CoT con ejemplos para mostrar el patrón de razonamiento deseado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Few-shot CoT: ejemplos con razonamiento paso a paso\n",
    "def few_shot_cot():\n",
    "    print(\"=== FEW-SHOT CHAIN-OF-THOUGHT ===\")\n",
    "    \n",
    "    # Nuevo problema para resolver\n",
    "    nuevo_problema = \"Un parking cobra 3€ la primera hora y 2€ cada hora adicional. Si alguien paga 15€, ¿cuántas horas estuvo estacionado?\"\n",
    "    \n",
    "    # Prompt con ejemplos de razonamiento\n",
    "    prompt_few_shot_cot = f\"\"\"Resuelve problemas matemáticos mostrando el razonamiento paso a paso:\n",
    "    \n",
    "Problema: Una pizza cuesta 12€ y cada ingrediente extra cuesta 1.50€. Si Pedro paga 18€, ¿cuántos ingredientes extra pidió?\n",
    "Razonamiento:\n",
    "1. Precio base de la pizza: 12€\n",
    "2. Total pagado: 18€\n",
    "3. Dinero gastado en extras: 18€ - 12€ = 6€\n",
    "4. Costo por ingrediente extra: 1.50€\n",
    "5. Número de ingredientes: 6€ ÷ 1.50€ = 4 ingredientes\n",
    "Respuesta: Pedro pidió 4 ingredientes extra.\n",
    "    \n",
    "Problema: En una clase hay 24 estudiantes. Si se forman grupos de 6 estudiantes cada uno, ¿cuántos grupos se pueden formar? Si sobra algún estudiante, ¿cuántos?\n",
    "Razonamiento:\n",
    "1. Total de estudiantes: 24\n",
    "2. Estudiantes por grupo: 6\n",
    "3. División: 24 ÷ 6 = 4 grupos exactos\n",
    "4. Verificación: 4 × 6 = 24 estudiantes\n",
    "5. Resto: 24 - 24 = 0 estudiantes sobran\n",
    "Respuesta: Se pueden formar 4 grupos completos y no sobra ningún estudiante.\n",
    "    \n",
    "Problema: {nuevo_problema}\n",
    "Razonamiento:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_few_shot_cot)])\n",
    "        print(\"PROBLEMA A RESOLVER:\")\n",
    "        print(nuevo_problema)\n",
    "        print(\"\\nSOLUCIÓN CON RAZONAMIENTO:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Verificar si siguió el patrón\n",
    "        razonamiento = response.content\n",
    "        tiene_pasos_numerados = bool(re.search(r'\\d+\\.', razonamiento))\n",
    "        tiene_calculos = any(op in razonamiento for op in ['=', '+', '-', '*', '/', '€'])\n",
    "        tiene_respuesta_final = 'respuesta' in razonamiento.lower()\n",
    "        \n",
    "        print(\"\\n=== ANÁLISIS DEL PATRÓN ===\")\n",
    "        print(f\"✓ Pasos numerados: {'Sí' if tiene_pasos_numerados else 'No'}\")\n",
    "        print(f\"✓ Cálculos explícitos: {'Sí' if tiene_calculos else 'No'}\")\n",
    "        print(f\"✓ Respuesta final clara: {'Sí' if tiene_respuesta_final else 'No'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar few-shot CoT\n",
    "import re\n",
    "few_shot_cot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoT para Razonamiento Lógico\n",
    "\n",
    "Chain-of-Thought es especialmente poderoso para problemas de lógica y deducción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoT para problemas de lógica\n",
    "def cot_razonamiento_logico():\n",
    "    print(\"=== CoT PARA RAZONAMIENTO LÓGICO ===\")\n",
    "    \n",
    "    # Problema de lógica clásico\n",
    "    problema_logica = \"\"\"En una mesa redonda se sientan 5 personas: Ana, Bruno, Carlos, Diana y Elena.\n",
    "    - Ana no está al lado de Bruno\n",
    "    - Carlos está exactamente frente a Diana\n",
    "    - Elena está al lado derecho de Ana\n",
    "    - Bruno está al lado de Carlos\n",
    "    \n",
    "¿Cuál es la disposición completa alrededor de la mesa?\"\"\"\n",
    "    \n",
    "    prompt_logica = f\"\"\"Resuelve este problema de lógica paso a paso:\n",
    "    \n",
    "{problema_logica}\n",
    "    \n",
    "Razona sistemáticamente:\n",
    "1. Identifica las restricciones\n",
    "2. Establece relaciones conocidas\n",
    "3. Deduce posiciones paso a paso\n",
    "4. Verifica que se cumplan todas las condiciones\n",
    "    \n",
    "Proceso de deducción:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_logica)])\n",
    "        print(\"PROBLEMA DE LÓGICA:\")\n",
    "        print(problema_logica)\n",
    "        print(\"\\nPROCESO DE RAZONAMIENTO:\")\n",
    "        print(response.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar razonamiento lógico\n",
    "cot_razonamiento_logico()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoT para análisis de casos complejos\n",
    "def cot_analisis_complejo():\n",
    "    print(\"=== CoT PARA ANÁLISIS COMPLEJO ===\")\n",
    "    \n",
    "    # Caso de negocio complejo\n",
    "    caso_negocio = \"\"\"Una startup de software tiene las siguientes métricas:\n",
    "    - 10,000 usuarios activos mensuales\n",
    "    - Tasa de conversión a premium: 5%\n",
    "    - Precio premium: 29€/mes\n",
    "    - Costo de adquisición por usuario: 15€\n",
    "    - Retención mensual: 85%\n",
    "    - Costos operativos mensuales: 12,000€\n",
    "    \n",
    "La empresa está considerando reducir el precio a 19€/mes para aumentar la conversión a 8%. \n",
    "¿Es una buena decisión financiera?\"\"\"\n",
    "    \n",
    "    prompt_analisis = f\"\"\"Analiza este caso de negocio paso a paso:\n",
    "    \n",
    "{caso_negocio}\n",
    "    \n",
    "Estructura tu análisis:\n",
    "1. Calcula métricas del escenario actual\n",
    "2. Calcula métricas del escenario propuesto\n",
    "3. Compara ingresos y costos\n",
    "4. Considera factores adicionales\n",
    "5. Proporciona recomendación fundamentada\n",
    "    \n",
    "Análisis detallado:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_analisis)])\n",
    "        print(\"CASO DE NEGOCIO:\")\n",
    "        print(caso_negocio)\n",
    "        print(\"\\nANÁLISIS PASO A PASO:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Verificar completitud del análisis\n",
    "        analisis = response.content.lower()\n",
    "        elementos_clave = [\n",
    "            'ingresos', 'costos', 'beneficio', 'actual', 'propuesto', \n",
    "            'recomendación', 'conversión', 'usuarios'\n",
    "        ]\n",
    "        elementos_presentes = sum(1 for elemento in elementos_clave if elemento in analisis)\n",
    "        \n",
    "        print(f\"\\n=== COMPLETITUD DEL ANÁLISIS ===\")\n",
    "        print(f\"✓ Elementos clave cubiertos: {elementos_presentes}/{len(elementos_clave)}\")\n",
    "        print(f\"✓ Análisis completo: {'Sí' if elementos_presentes >= 6 else 'Parcial'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar análisis complejo\n",
    "cot_analisis_complejo()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Técnicas Avanzadas de CoT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Técnica 1: CoT con Auto-Verificación\n",
    "def cot_con_verificacion():\n",
    "    print(\"=== CoT CON AUTO-VERIFICACIÓN ===\")\n",
    "    \n",
    "    problema = \"Una piscina se llena con dos bombas. La bomba A la llena en 4 horas, la bomba B en 6 horas. Si funcionan juntas, ¿en cuánto tiempo llenan la piscina?\"\n",
    "    \n",
    "    prompt_verificacion = f\"\"\"Resuelve este problema paso a paso y luego verifica tu respuesta:\n",
    "    \n",
    "{problema}\n",
    "    \n",
    "PASO 1 - RESOLUCIÓN:\n",
    "Piensa paso a paso para encontrar la solución.\n",
    "    \n",
    "PASO 2 - VERIFICACIÓN:\n",
    "Revisa tu cálculo usando un método diferente o verificando que los números tienen sentido.\n",
    "    \n",
    "PASO 3 - RESPUESTA FINAL:\n",
    "Confirma tu respuesta final.\n",
    "    \n",
    "Proceso completo:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_verificacion)])\n",
    "        print(\"PROBLEMA:\")\n",
    "        print(problema)\n",
    "        print(\"\\nSOLUCIÓN CON AUTO-VERIFICACIÓN:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Verificar estructura\n",
    "        contenido = response.content.lower()\n",
    "        tiene_resolucion = 'paso 1' in contenido or 'resolución' in contenido\n",
    "        tiene_verificacion = 'paso 2' in contenido or 'verificación' in contenido\n",
    "        tiene_final = 'paso 3' in contenido or 'final' in contenido\n",
    "        \n",
    "        print(\"\\n=== ESTRUCTURA ===\")\n",
    "        print(f\"✓ Resolución: {'Sí' if tiene_resolucion else 'No'}\")\n",
    "        print(f\"✓ Verificación: {'Sí' if tiene_verificacion else 'No'}\")\n",
    "        print(f\"✓ Respuesta final: {'Sí' if tiene_final else 'No'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar CoT con verificación\n",
    "cot_con_verificacion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Técnica 2: CoT Multi-Perspectiva\n",
    "def cot_multi_perspectiva():\n",
    "    print(\"=== CoT MULTI-PERSPECTIVA ===\")\n",
    "    \n",
    "    dilema = \"\"\"Una empresa de delivery está considerando implementar un algoritmo de IA \n",
    "    para optimizar rutas que podría reducir costos en 20% pero eliminaría 100 empleos \n",
    "    de repartidores. ¿Debería implementarlo?\"\"\"\n",
    "    \n",
    "    prompt_multi = f\"\"\"Analiza este dilema desde múltiples perspectivas:\n",
    "    \n",
    "{dilema}\n",
    "    \n",
    "Analiza paso a paso desde cada perspectiva:\n",
    "    \n",
    "PERSPECTIVA 1 - FINANCIERA:\n",
    "- Beneficios económicos\n",
    "- Costos de implementación\n",
    "- ROI a corto y largo plazo\n",
    "    \n",
    "PERSPECTIVA 2 - SOCIAL/ÉTICA:\n",
    "- Impacto en empleados\n",
    "- Responsabilidad social corporativa\n",
    "- Percepción pública\n",
    "    \n",
    "PERSPECTIVA 3 - ESTRATÉGICA:\n",
    "- Competitividad del mercado\n",
    "- Innovación tecnológica\n",
    "- Sostenibilidad del negocio\n",
    "    \n",
    "SÍNTESIS:\n",
    "- Integra las perspectivas\n",
    "- Propone soluciones alternativas\n",
    "- Recomienda curso de acción\n",
    "    \n",
    "Análisis completo:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_multi)])\n",
    "        print(\"DILEMA EMPRESARIAL:\")\n",
    "        print(dilema)\n",
    "        print(\"\\nANÁLISIS MULTI-PERSPECTIVA:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Verificar cobertura de perspectivas\n",
    "        analisis = response.content.lower()\n",
    "        perspectivas = ['financiera', 'social', 'ética', 'estratégica', 'síntesis']\n",
    "        perspectivas_cubiertas = sum(1 for p in perspectivas if p in analisis)\n",
    "        \n",
    "        print(f\"\\n=== COBERTURA DEL ANÁLISIS ===\")\n",
    "        print(f\"✓ Perspectivas cubiertas: {perspectivas_cubiertas}/{len(perspectivas)}\")\n",
    "        print(f\"✓ Análisis integral: {'Sí' if perspectivas_cubiertas >= 4 else 'Parcial'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar análisis multi-perspectiva\n",
    "cot_multi_perspectiva()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CoT para Debugging de Código\n",
    "\n",
    "Una aplicación práctica muy útil: usar CoT para analizar y debuggear código."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CoT para debugging de código\n",
    "def cot_debugging():\n",
    "    print(\"=== CoT PARA DEBUGGING DE CÓDIGO ===\")\n",
    "    \n",
    "    codigo_con_bug = '''def calcular_promedio(numeros):\n",
    "    total = 0\n",
    "    for numero in numeros:\n",
    "        total += numero\n",
    "    promedio = total / len(numeros)\n",
    "    return promedio\n",
    "\n",
    "# Uso\n",
    "datos = []\n",
    "resultado = calcular_promedio(datos)\n",
    "print(f\"El promedio es: {resultado}\")'''\n",
    "    \n",
    "    prompt_debugging = f\"\"\"Analiza este código paso a paso para encontrar problemas:\n",
    "    \n",
    "```python\n",
    "{codigo_con_bug}\n",
    "```\n",
    "    \n",
    "PASO 1 - COMPRENSIÓN:\n",
    "¿Qué se supone que hace este código?\n",
    "    \n",
    "PASO 2 - ANÁLISIS LÍNEA POR LÍNEA:\n",
    "Examina cada línea en busca de problemas potenciales.\n",
    "    \n",
    "PASO 3 - IDENTIFICACIÓN DE PROBLEMAS:\n",
    "¿Qué errores o problemas específicos encuentras?\n",
    "    \n",
    "PASO 4 - CASOS PROBLEMÁTICOS:\n",
    "¿En qué situaciones fallaría este código?\n",
    "    \n",
    "PASO 5 - SOLUCIÓN:\n",
    "¿Cómo arreglarías estos problemas?\n",
    "    \n",
    "Análisis de debugging:\"\"\"\n",
    "    \n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_debugging)])\n",
    "        print(\"CÓDIGO A ANALIZAR:\")\n",
    "        print(codigo_con_bug)\n",
    "        print(\"\\nANÁLISIS DE DEBUGGING:\")\n",
    "        print(response.content)\n",
    "        \n",
    "        # Verificar si encontró el problema principal\n",
    "        analisis = response.content.lower()\n",
    "        encontro_division_cero = any(term in analisis for term in ['división', 'cero', 'vacía', 'empty'])\n",
    "        propuso_solucion = 'if' in analisis or 'len(' in analisis or 'excepción' in analisis\n",
    "        \n",
    "        print(f\"\\n=== EFECTIVIDAD DEL DEBUGGING ===\")\n",
    "        print(f\"✓ Identificó división por cero: {'Sí' if encontro_division_cero else 'No'}\")\n",
    "        print(f\"✓ Propuso solución: {'Sí' if propuso_solucion else 'No'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar debugging\n",
    "cot_debugging()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Limitaciones y Consideraciones de CoT\n",
    "\n",
    "### ✅ Cuándo Usar CoT:\n",
    "- Problemas matemáticos complejos\n",
    "- Razonamiento lógico multi-paso\n",
    "- Análisis que requiere transparencia\n",
    "- Cuando necesitas verificar el proceso\n",
    "- Problemas donde el \"por qué\" es importante\n",
    "\n",
    "### ⚠️ Limitaciones:\n",
    "- **Más tokens**: Respuestas más largas = mayor costo\n",
    "- **Tiempo**: Razonamiento paso a paso toma más tiempo\n",
    "- **Complejidad innecesaria**: Para problemas simples puede ser excesivo\n",
    "- **Razonamiento erróneo**: Puede mostrar lógica incorrecta convincente\n",
    "\n",
    "### 🎯 Mejores Prácticas:\n",
    "1. **Estructura clara**: Define pasos específicos\n",
    "2. **Verificación**: Incluye auto-verificación cuando sea posible\n",
    "3. **Ejemplos**: Usa few-shot para mostrar patrón deseado\n",
    "4. **Temperatura baja**: Para razonamiento más consistente\n",
    "5. **Validación externa**: Verifica respuestas críticas independientemente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ejercicio final: Diseña tu propio CoT prompt\n",
    "def ejercicio_cot():\n",
    "    print(\"=== EJERCICIO: DISEÑA TU CoT PROMPT ===\")\n",
    "    print(\"\\nTarea: Crear un sistema CoT para análisis de inversión\")\n",
    "    print(\"\\nEscenario:\")\n",
    "    print(\"Una persona tiene 10,000€ para invertir y está considerando tres opciones:\")\n",
    "    print(\"1. Acciones de tech (retorno esperado 12% anual, riesgo alto)\")\n",
    "    print(\"2. Bonos gubernamentales (retorno 3% anual, riesgo bajo)\")\n",
    "    print(\"3. Fondo mixto (retorno 7% anual, riesgo medio)\")\n",
    "    print(\"\\nLa persona es joven (25 años) y puede asumir riesgo moderado.\")\n",
    "    \n",
    "    # Template para el estudiante\n",
    "    template_cot = \"\"\"\n",
    "    # TU PROMPT CoT AQUÍ:\n",
    "    \n",
    "    Analiza esta decisión de inversión paso a paso:\n",
    "    \n",
    "    [ESCENARIO]\n",
    "    \n",
    "    PASO 1 - PERFIL DEL INVERSOR:\n",
    "    - Analiza edad, tolerancia al riesgo, horizonte temporal\n",
    "    \n",
    "    PASO 2 - ANÁLISIS DE OPCIONES:\n",
    "    - Evalúa cada opción: retorno, riesgo, liquidez\n",
    "    \n",
    "    PASO 3 - ESTRATEGIA DE DIVERSIFICACIÓN:\n",
    "    - Considera combinar opciones\n",
    "    \n",
    "    PASO 4 - RECOMENDACIÓN:\n",
    "    - Proporciona recomendación específica con justificación\n",
    "    \n",
    "    Análisis de inversión:\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nDiseña un prompt CoT estructurado:\")\n",
    "    print(template_cot)\n",
    "    \n",
    "    # Prompt de ejemplo bien diseñado\n",
    "    prompt_ejemplo = \"\"\"Analiza esta decisión de inversión usando razonamiento paso a paso:\n",
    "    \n",
    "SITUACIÓN:\n",
    "Inversor de 25 años con 10,000€ considerando:\n",
    "- Acciones tech: 12% retorno anual, riesgo alto\n",
    "- Bonos: 3% retorno anual, riesgo bajo  \n",
    "- Fondo mixto: 7% retorno anual, riesgo medio\n",
    "Tolerancia: riesgo moderado\n",
    "    \n",
    "PASO 1 - PERFIL DEL INVERSOR:\n",
    "Analiza edad, horizonte temporal y tolerancia al riesgo.\n",
    "    \n",
    "PASO 2 - EVALUACIÓN DE OPCIONES:\n",
    "Para cada opción, calcula:\n",
    "- Valor esperado en 10 años\n",
    "- Nivel de riesgo vs. perfil\n",
    "- Pros y contras específicos\n",
    "    \n",
    "PASO 3 - ESTRATEGIA DE PORTFOLIO:\n",
    "Considera distribución óptima entre opciones basada en:\n",
    "- Diversificación de riesgo\n",
    "- Maximización de retorno ajustado por riesgo\n",
    "- Liquidez y flexibilidad\n",
    "    \n",
    "PASO 4 - RECOMENDACIÓN FINAL:\n",
    "Proporciona distribución específica (porcentajes) con:\n",
    "- Justificación detallada\n",
    "- Proyección a 10 años\n",
    "- Consideraciones adicionales\n",
    "    \n",
    "Análisis completo:\"\"\"\n",
    "    \n",
    "    print(\"\\n=== PROMPT DE REFERENCIA ===\")\n",
    "    print(prompt_ejemplo)\n",
    "    \n",
    "    # Ejecutar el prompt ejemplo\n",
    "    print(\"\\n=== RESULTADO DEL ANÁLISIS ===\")\n",
    "    try:\n",
    "        response = llm.invoke([HumanMessage(content=prompt_ejemplo)])\n",
    "        print(response.content)\n",
    "        \n",
    "        # Análisis de la respuesta\n",
    "        analisis = response.content.lower()\n",
    "        elementos = ['perfil', 'evaluación', 'portfolio', 'recomendación', '%', '€', 'años']\n",
    "        elementos_presentes = sum(1 for elem in elementos if elem in analisis)\n",
    "        \n",
    "        print(f\"\\n=== CALIDAD DEL ANÁLISIS ===\")\n",
    "        print(f\"✓ Elementos clave: {elementos_presentes}/{len(elementos)}\")\n",
    "        print(f\"✓ Análisis completo: {'Sí' if elementos_presentes >= 5 else 'Parcial'}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "\n",
    "# Ejecutar ejercicio\n",
    "ejercicio_cot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Chain-of-Thought** mejora dramáticamente la precisión en problemas complejos\n",
    "2. **Zero-shot CoT** es tan simple como agregar \"piensa paso a paso\"\n",
    "3. **Few-shot CoT** combina ejemplos con razonamiento para mejor control\n",
    "4. **Estructura explícita** guía el razonamiento hacia análisis completos\n",
    "5. **Auto-verificación** aumenta la confiabilidad de las respuestas\n",
    "\n",
    "## Próximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos **Técnicas Avanzadas** como Tree of Thoughts (ToT), Self-Consistency, y otras metodologías cutting-edge que llevan el prompt engineering al siguiente nivel.\n",
    "\n",
    "### Para Practicar:\n",
    "1. Aplica CoT a problemas de tu dominio específico\n",
    "2. Experimenta con diferentes niveles de estructura\n",
    "3. Compara precisión con y sin CoT\n",
    "4. Desarrolla patrones de verificación personalizados"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
