{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7ex6utq4wn",
   "source": "## Ejercicios Prácticos\n\n### Ejercicio 1: Experimentar con Diferentes Modelos\nModifica el código para probar diferentes modelos disponibles (si tienes acceso):\n- gpt-3.5-turbo\n- gpt-4\n- gpt-4o-mini\n\n### Ejercicio 2: Crear un Asistente Especializado\nDiseña un mensaje de sistema para crear un asistente especializado en un tema específico (ejemplo: finanzas, salud, educación).\n\n### Ejercicio 3: Optimización de Tokens\nExperimenta con diferentes valores de max_tokens para encontrar el equilibrio entre respuesta completa y eficiencia de costos.\n\n## Conceptos Clave Aprendidos\n\n1. **Configuración segura** de APIs usando variables de entorno\n2. **Parámetros básicos** para controlar el comportamiento del modelo\n3. **Manejo de errores** en llamadas a APIs\n4. **Roles de mensajes** (system, user, assistant)\n5. **Monitoreo de uso** de tokens y costos\n\n## Próximos Pasos\n\nEn el siguiente notebook exploraremos cómo LangChain simplifica y abstrae estas operaciones, proporcionando herramientas más poderosas para el desarrollo de aplicaciones con LLMs.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "j1b57r1oeo",
   "source": "# Ejemplo con mensaje de sistema\ndef usar_mensaje_sistema():\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\n                    \"role\": \"system\", \n                    \"content\": \"Eres un experto en tecnología que explica conceptos complejos de manera simple y amigable. Siempre incluyes ejemplos prácticos.\"\n                },\n                {\n                    \"role\": \"user\", \n                    \"content\": \"¿Qué es una API?\"\n                }\n            ],\n            temperature=0.7,\n            max_tokens=200\n        )\n        \n        print(\"=== Respuesta con Mensaje de Sistema ===\")\n        print(response.choices[0].message.content)\n        \n    except Exception as e:\n        print(f\"Error: {e}\")\n\n# Ejecutar función\nusar_mensaje_sistema()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "z2hpk12pr3f",
   "source": "## Usando Roles del Sistema\n\nEl rol \"system\" permite establecer el comportamiento y contexto del asistente antes de la conversación.",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "j48bg48xqs",
   "source": "# Comparando diferentes valores de temperature\ndef comparar_temperature():\n    prompt = \"Escribe una historia muy corta sobre un robot que aprende a cocinar.\"\n    \n    temperatures = [0.1, 0.5, 0.9]\n    \n    for temp in temperatures:\n        print(f\"\\n{'='*50}\")\n        print(f\"TEMPERATURE: {temp}\")\n        print('='*50)\n        \n        try:\n            response = client.chat.completions.create(\n                model=\"gpt-4o\",\n                messages=[{\"role\": \"user\", \"content\": prompt}],\n                temperature=temp,\n                max_tokens=100\n            )\n            \n            print(response.choices[0].message.content)\n            print(f\"\\nTokens usados: {response.usage.total_tokens}\")\n            \n        except Exception as e:\n            print(f\"Error: {e}\")\n\n# Ejecutar comparación\ncomparar_temperature()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "etq98uy4her",
   "source": "## Explorando Parámetros de Configuración\n\nLos parámetros más importantes al hacer llamadas a LLMs son:\n\n- **temperature**: Controla la creatividad (0.0 = determinístico, 1.0 = muy creativo)\n- **max_tokens**: Límite de tokens en la respuesta\n- **model**: El modelo específico a usar (gpt-4o, gpt-3.5-turbo, etc.)\n- **messages**: Array de mensajes con roles (system, user, assistant)",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "id": "fk2x0el1u1",
   "source": "# Primera llamada básica al modelo\ndef llamada_basica():\n    try:\n        response = client.chat.completions.create(\n            model=\"gpt-4o\",\n            messages=[\n                {\"role\": \"user\", \"content\": \"Hola, ¿cómo estás? Responde en una oración.\"}\n            ],\n            temperature=0.7,\n            max_tokens=150\n        )\n        \n        print(\"=== Respuesta del Modelo ===\")\n        print(response.choices[0].message.content)\n        print(\"\\n=== Información Técnica ===\")\n        print(f\"Modelo usado: {response.model}\")\n        print(f\"Tokens usados: {response.usage.total_tokens}\")\n        print(f\"Tokens de entrada: {response.usage.prompt_tokens}\")\n        print(f\"Tokens de salida: {response.usage.completion_tokens}\")\n        \n    except Exception as e:\n        print(f\"Error en la llamada: {e}\")\n        print(\"Verifica tu configuración y conexión a internet\")\n\n# Ejecutar la función\nllamada_basica()",
   "metadata": {},
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "id": "kfakrvh3xv",
   "source": "## Primera Llamada al Modelo\n\nAhora realizaremos nuestra primera llamada al modelo con diferentes configuraciones para entender los parámetros básicos.",
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "id": "7c95ec21",
   "metadata": {},
   "outputs": [],
   "source": "# 1. GitHub Models API - Conexión Directa con OpenAI Client\n\n## Objetivos de Aprendizaje\n- Configurar una conexión directa con GitHub Models usando el cliente OpenAI\n- Comprender los parámetros básicos de configuración de API\n- Implementar llamadas básicas a modelos de lenguaje\n- Aplicar mejores prácticas de seguridad con API keys\n\n## Introducción\nGitHub Models proporciona acceso a varios modelos de lenguaje mediante una API compatible con OpenAI. En este notebook aprenderemos a:\n1. Configurar el entorno y las credenciales\n2. Establecer una conexión con la API\n3. Realizar llamadas básicas al modelo\n4. Explorar diferentes parámetros de configuración\n\n## Instalación de Dependencias\n```bash\npip install openai\n```"
  },
  {
   "cell_type": "code",
   "id": "9e34c5aa",
   "metadata": {},
   "outputs": [],
   "source": "# Importar las bibliotecas necesarias\nfrom openai import OpenAI\nimport os\n\n# Verificar que tenemos las bibliotecas correctas\nprint(\"OpenAI library version:\", __import__('openai').__version__)\nprint(\"Python version:\", __import__('sys').version)"
  },
  {
   "cell_type": "code",
   "id": "bfc6b98e",
   "metadata": {},
   "outputs": [],
   "source": "# Configuración del cliente OpenAI para GitHub Models\ntry:\n    # Configurar el cliente con variables de entorno\n    client = OpenAI(\n        base_url=os.environ.get(\"GITHUB_BASE_URL\"),\n        api_key=os.environ.get(\"GITHUB_TOKEN\")\n    )\n    \n    # Verificar configuración (sin mostrar la API key completa por seguridad)\n    print(\"Base URL configurada:\", client.base_url)\n    print(\"API Key configurada:\", \"✓\" if client.api_key else \"✗\")\n    \n    if client.api_key:\n        print(\"API Key preview:\", client.api_key[:10] + \"...\" + client.api_key[-4:])\n    else:\n        print(\"⚠️  API Key no encontrada. Asegúrate de configurar GITHUB_TOKEN\")\n        \nexcept Exception as e:\n    print(f\"Error en configuración: {e}\")\n    print(\"Verifica que las variables de entorno estén configuradas correctamente\")"
  },
  {
   "cell_type": "markdown",
   "id": "hfq6f7p28kp",
   "source": "## Configuración de Variables de Entorno\n\nAntes de ejecutar el código, asegúrate de tener configuradas las siguientes variables de entorno:\n\n```bash\nexport GITHUB_BASE_URL=\"https://models.inference.ai.azure.com\"\nexport GITHUB_TOKEN=\"tu_token_de_github_aqui\"\n```\n\n**Mejores Prácticas de Seguridad:**\n- Nunca hardcodees API keys en el código\n- Usa variables de entorno o archivos .env\n- No compartas credenciales en repositorios públicos\n- Rota las API keys regularmente",
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}