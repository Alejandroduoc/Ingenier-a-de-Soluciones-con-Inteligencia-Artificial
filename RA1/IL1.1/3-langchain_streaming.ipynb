{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "hfn0f7nyumn",
   "metadata": {},
   "source": [
    "# 3. LangChain Streaming - Respuestas en Tiempo Real\n",
    "\n",
    "## Objetivos de Aprendizaje\n",
    "- Comprender qué es el streaming y cuándo usarlo\n",
    "- Implementar streaming con LangChain\n",
    "- Manejar chunks de datos en tiempo real\n",
    "- Construir interfaces de usuario reactivas\n",
    "\n",
    "## ¿Qué es el Streaming?\n",
    "\n",
    "El streaming permite recibir la respuesta del modelo **token por token** conforme se genera, en lugar de esperar a que termine completamente. Esto mejora significativamente la experiencia de usuario en aplicaciones interactivas.\n",
    "\n",
    "### Ventajas del Streaming:\n",
    "- **Percepción de velocidad**: El usuario ve progreso inmediato\n",
    "- **Mejor UX**: Interfaces más reactivas e interactivas  \n",
    "- **Engagement**: Mantiene la atención del usuario\n",
    "- **Debugging**: Permite ver el proceso de generación\n",
    "\n",
    "### Casos de Uso Ideales:\n",
    "- Chatbots y asistentes conversacionales\n",
    "- Generación de contenido largo\n",
    "- Aplicaciones web interactivas\n",
    "- Demostraciones en vivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4aa694f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bibliotecas importadas correctamente para streaming\n"
     ]
    }
   ],
   "source": [
    "# Importar bibliotecas necesarias\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain.schema import HumanMessage\n",
    "import os\n",
    "import time\n",
    "\n",
    "print(\"Bibliotecas importadas correctamente para streaming\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13f037cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Modelo configurado con streaming habilitado\n",
      "Modelo: gpt-4o\n",
      "Streaming: True\n"
     ]
    }
   ],
   "source": [
    "# Configuración del modelo con streaming habilitado\n",
    "try:\n",
    "    llm = ChatOpenAI(\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "        model=\"gpt-4o\",\n",
    "        streaming=True,  # ¡Importante: habilitar streaming!\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    print(\"✓ Modelo configurado con streaming habilitado\")\n",
    "    print(f\"Modelo: {llm.model_name}\")\n",
    "    print(f\"Streaming: {llm.streaming}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"✗ Error en configuración: {e}\")\n",
    "    print(\"Verifica las variables de entorno\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06da0d27",
   "metadata": {},
   "source": [
    "## Streaming Básico\n",
    "\n",
    "El método `.stream()` devuelve un generador que produce chunks de texto conforme se generan."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b1f31f5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING EN TIEMPO REAL ===\n",
      "Generando respuesta...\n",
      "--------------------------------------------------\n",
      "Había una vez un programador llamado Martín, un hombre reservado y metódico que dedicaba la mayor parte de su tiempo a escribir líneas de código en la soledad de su pequeño apartamento. Su vida transcurría en una rutina predecible: trabajar, beber café, solucionar errores, dormir, y repetir. Martín era un experto en su oficio, pero siempre había sentido que algo faltaba en su vida, aunque no sabía exactamente qué.\n",
      "\n",
      "Una noche, mientras trabajaba en un proyecto personal, Martín se encontró con un archivo misterioso en su computadora. El archivo no tenía nombre y parecía haber aparecido de la nada. A pesar de que era meticuloso con la seguridad de su sistema, no pudo resistirse a abrirlo.\n",
      "\n",
      "Dentro del archivo encontró un fragmento de código que no se parecía a nada que hubiese visto antes. Las líneas parecían brillar tenuemente, como si estuvieran vivas, y las palabras estaban escritas en un lenguaje que mezclaba símbolos matemáticos, palabras en idiomas desconocidos y lo que parecía ser poesía.\n",
      "\n",
      "Intrigado, Martín comenzó a estudiar el código. A medida que lo analizaba, se dio cuenta de que no se trataba solo de programación convencional. Era algo más. Cada línea parecía contener una intención, una emoción, una chispa de algo indescriptible. Sin darse cuenta, Martín empezó a reescribir partes del código, guiado por una intuición que nunca antes había experimentado.\n",
      "\n",
      "Cuando ejecutó el programa por primera vez, la pantalla de su computadora se apagó de repente, y un destello de luz inundó la habitación. Al abrir los ojos, Martín se encontró de pie en un bosque brillante y surrealista, lleno de colores imposibles y criaturas que parecían estar hechas de energía pura. Se dio cuenta de que el código no era solo un programa: era un portal a otro mundo, un mundo donde la lógica y la magia se entrelazaban.\n",
      "\n",
      "En este nuevo mundo, Martín descubrió que el código que escribía tenía el poder de alterar la realidad. Podía crear puentes con solo teclear una función, invocar lluvias de estrellas ajustando un bucle, o incluso comunicarse con las criaturas del bosque a través de variables y algoritmos. Lo que antes era solo una herramienta técnica se había convertido en un lenguaje universal, capaz de dar forma a la esencia misma de ese lugar.\n",
      "\n",
      "Pasaron días —o quizás semanas, ya que el tiempo parecía comportarse de manera extraña en ese mundo—, y Martín se dio cuenta de que no quería regresar. Por primera vez en su vida, sentía que su trabajo tenía un propósito más profundo, una conexión con algo más grande que él mismo.\n",
      "\n",
      "Sin embargo, un día, una de las criaturas del bosque, una figura etérea que parecía un cúmulo de estrellas, le habló.\n",
      "\n",
      "—Martín, este mundo necesita equilibrio. No puedes quedarte para siempre, pero puedes llevar contigo lo que has aprendido.\n",
      "\n",
      "Martín despertó en su apartamento, frente a su monitor, con el archivo misterioso aún abierto. Pero algo había cambiado. Ahora, cada vez que escribía código, sentía una chispa de esa magia. Su trabajo dejó de ser solo líneas de texto; se convirtió en arte, en una forma de conectar con los demás y con el universo.\n",
      "\n",
      "Desde ese día, Martín no volvió a ser el mismo. Su código inspiró a otros, resolvió problemas que parecían imposibles y dejó una huella en el mundo. Y aunque nunca volvió a encontrar el portal, sabía que la magia seguía ahí, escondida entre las líneas de cada programa que escribía. \n",
      "--------------------------------------------------\n",
      "✓ Streaming completado\n"
     ]
    }
   ],
   "source": [
    "# Ejemplo básico de streaming\n",
    "def streaming_basico():\n",
    "    prompt = \"Cuéntame una historia corta sobre un programador que descubre la magia en el código\"\n",
    "    \n",
    "    print(\"=== STREAMING EN TIEMPO REAL ===\")\n",
    "    print(\"Generando respuesta...\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    try:\n",
    "        # stream() devuelve un generador de chunks\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            # Imprimir cada chunk sin nueva línea\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.01)  # Pequeña pausa para simular streaming visual\n",
    "            \n",
    "        print(\"\\n\" + \"-\" * 50)\n",
    "        print(\"✓ Streaming completado\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error en streaming: {e}\")\n",
    "\n",
    "# Ejecutar streaming básico\n",
    "streaming_basico()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6214408",
   "metadata": {},
   "source": [
    "## Comparación: Streaming vs No-Streaming\n",
    "\n",
    "Veamos la diferencia en experiencia de usuario entre ambos enfoques."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "db8e5874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== COMPARACIÓN: STREAMING vs NO-STREAMING ===\\n\n",
      "1. SIN STREAMING:\n",
      "--------------------\n",
      "Esperando respuesta completa...\n",
      "\\n[Respuesta recibida después de 3.20 segundos]\n",
      "Python es un lenguaje de programación altamente versátil y popular debido a sus numerosas ventajas. Su sintaxis simple y legible facilita el aprendizaje para principiantes y acelera el desarrollo para programadores experimentados, permitiendo centrarse en la lógica del problema en lugar de detalles técnicos complejos. Además, Python cuenta con una amplia biblioteca estándar y un ecosistema de paquetes de terceros que simplifican tareas como análisis de datos, desarrollo web, inteligencia artificial, automatización y más. Su naturaleza multiplataforma lo hace compatible con diversos sistemas operativos, y su comunidad activa proporciona soporte constante, recursos educativos y actualizaciones regulares. Estas características convierten a Python en una herramienta poderosa tanto para proyectos pequeños como para aplicaciones de gran escala en múltiples industrias.\n",
      "\\n============================================================\\n\n",
      "2. CON STREAMING:\n",
      "------------------\n",
      "Respuesta en tiempo real:\n",
      "Python es un lenguaje de programación sumamente versátil y accesible, lo que lo convierte en una excelente opción tanto para principiantes como para desarrolladores experimentados. Una de sus principales ventajas es su sintaxis clara y sencilla, que facilita la escritura y lectura del código, reduciendo el tiempo de desarrollo y minimizando errores. Además, cuenta con una vasta comunidad global que aporta soporte, documentación y una gran cantidad de bibliotecas y frameworks, como NumPy, pandas, Django o TensorFlow, que permiten abordar proyectos en áreas como análisis de datos, desarrollo web, inteligencia artificial y más. Python es también multiplataforma, lo que significa que los programas pueden ejecutarse en diferentes sistemas operativos sin grandes modificaciones. Su flexibilidad, combinado con su enfoque en la productividad y su capacidad para integrarse con otros lenguajes, lo convierten en una herramienta poderosa para resolver problemas complejos en diversos campos.\\n\\n[Streaming completado en 7.28 segundos]\n",
      "\\n============================================================\n",
      "OBSERVACIONES:\n",
      "- Sin streaming: El usuario espera sin feedback\n",
      "- Con streaming: El usuario ve progreso inmediato\n",
      "- Mejor percepción de velocidad con streaming\n",
      "- Streaming es especial para respuestas largas\n"
     ]
    }
   ],
   "source": [
    "# Comparación entre streaming y no-streaming\n",
    "def comparar_streaming():\n",
    "    # Modelo sin streaming\n",
    "    llm_no_stream = ChatOpenAI(\n",
    "        base_url=os.getenv(\"OPENAI_BASE_URL\"),\n",
    "        api_key=os.getenv(\"GITHUB_TOKEN\"),\n",
    "        model=\"gpt-4o\",\n",
    "        streaming=False,  # Sin streaming\n",
    "        temperature=0.7\n",
    "    )\n",
    "    \n",
    "    prompt = \"Escribe un párrafo sobre las ventajas de la programación en Python\"\n",
    "    \n",
    "    print(\"=== COMPARACIÓN: STREAMING vs NO-STREAMING ===\\\\n\")\n",
    "    \n",
    "    # 1. Sin streaming\n",
    "    print(\"1. SIN STREAMING:\")\n",
    "    print(\"-\" * 20)\n",
    "    print(\"Esperando respuesta completa...\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        response = llm_no_stream.invoke([HumanMessage(content=prompt)])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        print(f\"\\\\n[Respuesta recibida después de {end_time - start_time:.2f} segundos]\")\n",
    "        print(response.content)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60 + \"\\\\n\")\n",
    "    \n",
    "    # 2. Con streaming\n",
    "    print(\"2. CON STREAMING:\")\n",
    "    print(\"-\" * 18)\n",
    "    print(\"Respuesta en tiempo real:\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            print(chunk.content, end=\"\", flush=True)\n",
    "            time.sleep(0.03)  # Simular pausa para efecto visual\n",
    "        \n",
    "        end_time = time.time()\n",
    "        print(f\"\\\\n\\\\n[Streaming completado en {end_time - start_time:.2f} segundos]\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e}\")\n",
    "    \n",
    "    print(\"\\\\n\" + \"=\"*60)\n",
    "    print(\"OBSERVACIONES:\")\n",
    "    print(\"- Sin streaming: El usuario espera sin feedback\")\n",
    "    print(\"- Con streaming: El usuario ve progreso inmediato\")\n",
    "    print(\"- Mejor percepción de velocidad con streaming\")\n",
    "    print(\"- Streaming es especial para respuestas largas\")\n",
    "\n",
    "# Ejecutar comparación\n",
    "comparar_streaming()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "725ad79d",
   "metadata": {},
   "source": [
    "## Implementación de un Chatbot Simple con Streaming\n",
    "\n",
    "Creemos un chatbot básico que demuestre el streaming en un contexto práctico."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05a03cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== CHATBOT CON STREAMING ===\n",
      "Escribe 'salir' para terminar la conversación\\n\n",
      "\\n🤖 Asistente: ¡Hola! 😊 ¿En qué puedo ayudarte hoy?\n",
      "\\n🤖 Asistente: ¡Claro! Aquí tienes un poema breve:  \n",
      "\n",
      "En el susurro del viento callado,  \n",
      "las estrellas dibujan sueños dorados,  \n",
      "y la noche abraza el alma cansada.  \n",
      "\n",
      "¿Qué te parece? 😊\n",
      "\\n🤖 Asistente: ¡De nada! 😊 Si necesitas ayuda con algo, no dudes en preguntar. Estoy aquí para ayudarte. 🚀\n",
      "\\n👋 ¡Hasta luego!\n",
      "\\n¡Gracias por usar el chatbot!\n",
      "💡 Descomenta la línea anterior para probar el chatbot interactivo\n"
     ]
    }
   ],
   "source": [
    "# Chatbot simple con streaming\n",
    "def chatbot_streaming():\n",
    "    print(\"=== CHATBOT CON STREAMING ===\")\n",
    "    print(\"Escribe 'salir' para terminar la conversación\\\\n\")\n",
    "    \n",
    "    # Configurar asistente con personalidad\n",
    "    system_message = \"\"\"Eres un asistente útil y amigable especializado en tecnología. \n",
    "    Respondes de manera clara y concisa, y siempre intentas ser educativo.\"\"\"\n",
    "    \n",
    "    while True:\n",
    "        # Obtener input del usuario\n",
    "        user_input = input(\"\\\\n🧑 Tú: \")\n",
    "        \n",
    "        if user_input.lower() in ['salir', 'exit', 'quit']:\n",
    "            print(\"\\\\n👋 ¡Hasta luego!\")\n",
    "            break\n",
    "            \n",
    "        if not user_input.strip():\n",
    "            continue\n",
    "            \n",
    "        print(\"\\\\n🤖 Asistente: \", end=\"\", flush=True)\n",
    "        \n",
    "        try:\n",
    "            # Streaming de la respuesta\n",
    "            messages = [\n",
    "                {\"role\": \"system\", \"content\": system_message},\n",
    "                {\"role\": \"user\", \"content\": user_input}\n",
    "            ]\n",
    "            \n",
    "            # Convertir a formato LangChain\n",
    "            from langchain.schema import SystemMessage\n",
    "            lc_messages = [\n",
    "                SystemMessage(content=system_message),\n",
    "                HumanMessage(content=user_input)\n",
    "            ]\n",
    "            \n",
    "            full_response = \"\"\n",
    "            for chunk in llm.stream(lc_messages):\n",
    "                content = chunk.content\n",
    "                print(content, end=\"\", flush=True)\n",
    "                full_response += content\n",
    "                time.sleep(0.02)\n",
    "                \n",
    "            print()  # Nueva línea al final\n",
    "            \n",
    "        except KeyboardInterrupt:\n",
    "            print(\"\\\\n\\\\n⏸️ Interrumpido por el usuario\")\n",
    "            break\n",
    "        except Exception as e:\n",
    "            print(f\"\\\\n❌ Error: {e}\")\n",
    "            \n",
    "    print(\"\\\\n¡Gracias por usar el chatbot!\")\n",
    "\n",
    "# Ejecutar chatbot (¡Pruébalo!)\n",
    "# chatbot_streaming()  # Descomenta esta línea para ejecutar\n",
    "\n",
    "print(\"💡 Descomenta la línea anterior para probar el chatbot interactivo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6060e43c",
   "metadata": {},
   "source": [
    "## Streaming Avanzado con Manejo de Chunks\n",
    "\n",
    "Podemos procesar cada chunk individualmente para crear experiencias más sofisticadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f86fa1cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== STREAMING AVANZADO CON ANÁLISIS ===\n",
      "Analizando chunks conforme llegan...\n",
      "\n",
      "¡Por supuesto! Vamos a des\\n[Progreso: 10 chunks, ~8 palabras]\\n\n",
      "glosar estos conceptos de manera sencilla:\n",
      "\n",
      "###\\n[Progreso: 20 chunks, ~18 palabras]\\n\n",
      " **¿Qué es la Inteligencia Artificial (IA\\n[Progreso: 30 chunks, ~28 palabras]\\n\n",
      ")?**\n",
      "La **Inteligencia Artificial (IA\\n[Progreso: 40 chunks, ~38 palabras]\\n\n",
      ")** es un campo de la informática que se centra\\n[Progreso: 50 chunks, ~48 palabras]\\n\n",
      " en la creación de sistemas capaces de realizar tareas que\\n[Progreso: 60 chunks, ~58 palabras]\\n\n",
      " normalmente requieren inteligencia humana. Estas tareas pueden incluir el\\n[Progreso: 70 chunks, ~68 palabras]\\n\n",
      " reconocimiento de voz, la toma de decisiones, la\\n[Progreso: 80 chunks, ~78 palabras]\\n\n",
      " resolución de problemas, el aprendizaje, la planificación y\\n[Progreso: 90 chunks, ~88 palabras]\\n\n",
      " la comprensión del lenguaje natural.\n",
      "\n",
      "En otras palabras,\\n[Progreso: 100 chunks, ~98 palabras]\\n\n",
      " la IA busca que las máquinas \"piensen\"\\n[Progreso: 110 chunks, ~108 palabras]\\n\n",
      " o actúen como humanos, aunque no necesariamente\\n[Progreso: 120 chunks, ~118 palabras]\\n\n",
      " de la misma manera que nuestro cerebro. Los sistemas\\n[Progreso: 130 chunks, ~128 palabras]\\n\n",
      " de IA pueden ser diseñados para tareas específicas (\\n[Progreso: 140 chunks, ~138 palabras]\\n\n",
      "IA estrecha o débil), como los asistentes\\n[Progreso: 150 chunks, ~148 palabras]\\n\n",
      " virtuales (por ejemplo, Siri o Alexa),\\n[Progreso: 160 chunks, ~158 palabras]\\n\n",
      " o para tareas más amplias y complejas (\\n[Progreso: 170 chunks, ~168 palabras]\\n\n",
      "IA general o fuerte), aunque esta última aún está\\n[Progreso: 180 chunks, ~178 palabras]\\n\n",
      " en desarrollo.\n",
      "\n",
      "---\n",
      "\n",
      "### **¿Qué es el\\n[Progreso: 190 chunks, ~188 palabras]\\n\n",
      " Machine Learning (ML) y cómo funciona?**\n",
      "\\n[Progreso: 200 chunks, ~198 palabras]\\n\n",
      "El **Machine Learning (Aprendizaje Automático\\n[Progreso: 210 chunks, ~208 palabras]\\n\n",
      ")** es una rama de la IA que permite a\\n[Progreso: 220 chunks, ~218 palabras]\\n\n",
      " las máquinas aprender de los datos y mejorar su rendimiento\\n[Progreso: 230 chunks, ~228 palabras]\\n\n",
      " en tareas específicas sin necesidad de ser programadas explíc\\n[Progreso: 240 chunks, ~238 palabras]\\n\n",
      "itamente para cada caso. En lugar de decirle\\n[Progreso: 250 chunks, ~248 palabras]\\n\n",
      " a una máquina exactamente qué hacer, se le proporciona\\n[Progreso: 260 chunks, ~258 palabras]\\n\n",
      " un conjunto de datos para que \"aprenda\"\\n[Progreso: 270 chunks, ~268 palabras]\\n\n",
      " y descubra patrones por sí misma.\n",
      "\n",
      "#### **\\n[Progreso: 280 chunks, ~278 palabras]\\n\n",
      "¿Cómo funciona el Machine Learning?**\n",
      "El proceso\\n[Progreso: 290 chunks, ~288 palabras]\\n\n",
      " de ML usualmente sigue estos pasos principales:\n",
      "\n",
      "1\\n[Progreso: 300 chunks, ~298 palabras]\\n\n",
      ". **Recolección de Datos:** \n",
      "  \\n[Progreso: 310 chunks, ~306 palabras]\\n\n",
      " Se recopilan datos relevantes (por ejemplo, imágenes\\n[Progreso: 320 chunks, ~316 palabras]\\n\n",
      ", texto, números, etc.) que servirán\\n[Progreso: 330 chunks, ~326 palabras]\\n\n",
      " como base para el aprendizaje.\n",
      "\n",
      "2. **Prepar\\n[Progreso: 340 chunks, ~336 palabras]\\n\n",
      "ación y Limpieza:** \n",
      "   Los datos se\\n[Progreso: 350 chunks, ~344 palabras]\\n\n",
      " organizan y se limpian para eliminar valores incorrect\\n[Progreso: 360 chunks, ~354 palabras]\\n\n",
      "os, duplicados o inconsistencias. Esto asegura\\n[Progreso: 370 chunks, ~364 palabras]\\n\n",
      " que el modelo pueda aprender correctamente.\n",
      "\n",
      "3. **\\n[Progreso: 380 chunks, ~374 palabras]\\n\n",
      "Elección del Algoritmo:** \n",
      "   Se\\n[Progreso: 390 chunks, ~382 palabras]\\n\n",
      " selecciona un algoritmo de aprendizaje. Algunos ejemplos comunes\\n[Progreso: 400 chunks, ~392 palabras]\\n\n",
      " son:\n",
      "   - **Regresión Lineal:**\\n[Progreso: 410 chunks, ~401 palabras]\\n\n",
      " Para predecir valores continuos (como los\\n[Progreso: 420 chunks, ~411 palabras]\\n\n",
      " precios de casas).\n",
      "   - **Árbol\\n[Progreso: 430 chunks, ~420 palabras]\\n\n",
      "es de Decisión:** Para clasificar o tomar\\n[Progreso: 440 chunks, ~430 palabras]\\n\n",
      " decisiones.\n",
      "   - **Redes Neuronales\\n[Progreso: 450 chunks, ~439 palabras]\\n\n",
      ":** Inspiradas en el cerebro humano, útiles para\\n[Progreso: 460 chunks, ~449 palabras]\\n\n",
      " tareas complejas como reconocimiento de imágenes.\n",
      "\n",
      "4.\\n[Progreso: 470 chunks, ~459 palabras]\\n\n",
      " **Entrenamiento del Modelo:** \n",
      "   El\\n[Progreso: 480 chunks, ~467 palabras]\\n\n",
      " modelo de ML procesa los datos de entrenamiento (un\\n[Progreso: 490 chunks, ~477 palabras]\\n\n",
      " subconjunto de los datos originales) y ajusta\\n[Progreso: 500 chunks, ~487 palabras]\\n\n",
      " sus parámetros internos para aprender patrones en los datos.\n",
      "\n",
      "\\n[Progreso: 510 chunks, ~497 palabras]\\n\n",
      "5. **Evaluación:** \n",
      "   Después del\\n[Progreso: 520 chunks, ~505 palabras]\\n\n",
      " entrenamiento, el modelo se prueba con datos nuevos (\\n[Progreso: 530 chunks, ~515 palabras]\\n\n",
      "datos de prueba) para medir su precisión y desempeño\\n[Progreso: 540 chunks, ~525 palabras]\\n\n",
      ".\n",
      "\n",
      "6. **Predicciones:** \n",
      "   Una\\n[Progreso: 550 chunks, ~533 palabras]\\n\n",
      " vez entrenado y evaluado, el modelo puede\\n[Progreso: 560 chunks, ~543 palabras]\\n\n",
      " hacer predicciones o tomar decisiones en base a nuevos\\n[Progreso: 570 chunks, ~553 palabras]\\n\n",
      " datos.\n",
      "\n",
      "---\n",
      "\n",
      "### **Tipos de Machine Learning**\n",
      "\\n[Progreso: 580 chunks, ~563 palabras]\\n\n",
      "Existen tres tipos principales de aprendizaje en ML:\n",
      "\n",
      "\\n[Progreso: 590 chunks, ~573 palabras]\\n\n",
      "1. **Aprendizaje Supervisado:** \n",
      "\\n[Progreso: 600 chunks, ~581 palabras]\\n\n",
      "   El modelo aprende a partir de datos etiquet\\n[Progreso: 610 chunks, ~591 palabras]\\n\n",
      "ados. Por ejemplo, si quieres que un modelo\\n[Progreso: 620 chunks, ~601 palabras]\\n\n",
      " detecte correos spam, le proporcionarías ejemplos\\n[Progreso: 630 chunks, ~611 palabras]\\n\n",
      " de correos etiquetados como \"spam\"\\n[Progreso: 640 chunks, ~621 palabras]\\n\n",
      " o \"no spam\".\n",
      "\n",
      "2. **Aprendiz\\n[Progreso: 650 chunks, ~631 palabras]\\n\n",
      "aje No Supervisado:** \n",
      "   El modelo trabaja\\n[Progreso: 660 chunks, ~639 palabras]\\n\n",
      " con datos no etiquetados y busca patrones o\\n[Progreso: 670 chunks, ~649 palabras]\\n\n",
      " agrupaciones por sí mismo. Por ejemplo, agr\\n[Progreso: 680 chunks, ~659 palabras]\\n\n",
      "upar clientes en segmentos según su comportamiento de compra.\n",
      "\n",
      "\\n[Progreso: 690 chunks, ~669 palabras]\\n\n",
      "3. **Aprendizaje por Refuerzo:**\\n[Progreso: 700 chunks, ~678 palabras]\\n\n",
      " \n",
      "   Aquí, el modelo aprende a través de\\n[Progreso: 710 chunks, ~687 palabras]\\n\n",
      " ensayo y error, recibiendo recompensas o\\n[Progreso: 720 chunks, ~697 palabras]\\n\n",
      " penalizaciones según sus acciones, como en el caso\\n[Progreso: 730 chunks, ~707 palabras]\\n\n",
      " de entrenar a una IA para jugar videojuegos.\n",
      "\n",
      "\\n[Progreso: 740 chunks, ~717 palabras]\\n\n",
      "---\n",
      "\n",
      "### **Conexión entre IA y Machine\\n[Progreso: 750 chunks, ~727 palabras]\\n\n",
      " Learning**\n",
      "El Machine Learning es una **subcategor\\n[Progreso: 760 chunks, ~737 palabras]\\n\n",
      "ía de la IA**. Mientras que la IA\\n[Progreso: 770 chunks, ~747 palabras]\\n\n",
      " es un concepto más amplio que incluye cualquier máquina que\\n[Progreso: 780 chunks, ~757 palabras]\\n\n",
      " simule inteligencia, el Machine Learning es un enfoque\\n[Progreso: 790 chunks, ~767 palabras]\\n\n",
      " específico para lograr esto mediante el aprendizaje a partir de\\n[Progreso: 800 chunks, ~777 palabras]\\n\n",
      " datos.\n",
      "\n",
      "Por ejemplo:\n",
      "- IA: Un coche\\n[Progreso: 810 chunks, ~787 palabras]\\n\n",
      " autónomo toma decisiones en tiempo real para conducir.\n",
      "\\n[Progreso: 820 chunks, ~797 palabras]\\n\n",
      "- ML: El coche autónomo utiliza ML para\\n[Progreso: 830 chunks, ~807 palabras]\\n\n",
      " reconocer señales de tráfico o peatones basándose en\\n[Progreso: 840 chunks, ~817 palabras]\\n\n",
      " datos previos.\n",
      "\n",
      "---\n",
      "\n",
      "En resumen, la inteligencia\\n[Progreso: 850 chunks, ~827 palabras]\\n\n",
      " artificial busca que las máquinas sean \"inteligentes\\n[Progreso: 860 chunks, ~837 palabras]\\n\n",
      "\", y el machine learning es una de las herramientas\\n[Progreso: 870 chunks, ~847 palabras]\\n\n",
      " más poderosas para lograrlo, ya que permite\\n[Progreso: 880 chunks, ~857 palabras]\\n\n",
      " a las máquinas aprender y adaptarse en lugar de\\n[Progreso: 890 chunks, ~867 palabras]\\n\n",
      " depender únicamente de reglas predefinidas.\\n\\n=== ESTADÍSTICAS FINALES ===\n",
      "Total de chunks: 899\n",
      "Palabras aproximadas: 875\n",
      "Caracteres totales: 4140\n",
      "Promedio chars/chunk: 4.6\n"
     ]
    }
   ],
   "source": [
    "# Streaming con análisis de chunks\n",
    "def streaming_avanzado():\n",
    "    prompt = \"Explica qué es la inteligencia artificial y cómo funciona el machine learning\"\n",
    "    \n",
    "    print(\"=== STREAMING AVANZADO CON ANÁLISIS ===\")\n",
    "    print(\"Analizando chunks conforme llegan...\\n\")\n",
    "    \n",
    "    # Variables para estadísticas\n",
    "    chunk_count = 0\n",
    "    total_content = \"\"\n",
    "    words_processed = 0\n",
    "    \n",
    "    try:\n",
    "        for chunk in llm.stream([HumanMessage(content=prompt)]):\n",
    "            chunk_count += 1\n",
    "            content = chunk.content\n",
    "            total_content += content\n",
    "            \n",
    "            # Contar palabras aproximadas\n",
    "            if content.strip():\n",
    "                words_in_chunk = len(content.split())\n",
    "                words_processed += words_in_chunk\n",
    "            \n",
    "            # Mostrar progreso cada 10 chunks\n",
    "            if chunk_count % 10 == 0:\n",
    "                print(f\"\\\\n[Progreso: {chunk_count} chunks, ~{words_processed} palabras]\\\\n\")\n",
    "            \n",
    "            # Imprimir el contenido\n",
    "            print(content, end=\"\", flush=True)\n",
    "            time.sleep(0.02)  # Pausa ligeramente más larga para ver el análisis\n",
    "        \n",
    "        # Estadísticas finales\n",
    "        print(f\"\\\\n\\\\n=== ESTADÍSTICAS FINALES ===\")\n",
    "        print(f\"Total de chunks: {chunk_count}\")\n",
    "        print(f\"Palabras aproximadas: {words_processed}\")\n",
    "        print(f\"Caracteres totales: {len(total_content)}\")\n",
    "        print(f\"Promedio chars/chunk: {len(total_content)/chunk_count if chunk_count > 0 else 0:.1f}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\\\n✗ Error: {e}\")\n",
    "\n",
    "# Ejecutar streaming avanzado\n",
    "streaming_avanzado()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac251a9d",
   "metadata": {},
   "source": [
    "## Consideraciones Técnicas del Streaming\n",
    "\n",
    "### Cuándo Usar Streaming:\n",
    "✅ **SÍ usar streaming:**\n",
    "- Respuestas largas (>100 tokens)\n",
    "- Aplicaciones interactivas\n",
    "- Chatbots y asistentes\n",
    "- Demostraciones en vivo\n",
    "- Cuando la UX es prioritaria\n",
    "\n",
    "❌ **NO usar streaming:**\n",
    "- Respuestas muy cortas\n",
    "- Procesamiento batch\n",
    "- APIs de backend sin interfaz\n",
    "- Cuando necesitas la respuesta completa antes de procesar\n",
    "\n",
    "### Mejores Prácticas:\n",
    "1. **Manejo de errores**: Siempre incluye try/catch\n",
    "2. **Indicadores visuales**: Muestra progreso al usuario\n",
    "3. **Cancelación**: Permite al usuario interrumpir\n",
    "4. **Buffer management**: Para interfaces web, considera buffering\n",
    "5. **Performance**: Monitorea el uso de recursos\n",
    "\n",
    "## Ejercicios Prácticos\n",
    "\n",
    "### Ejercicio 1: Indicador de Progreso\n",
    "Modifica el código para mostrar un indicador de progreso (spinner, barra, porcentaje).\n",
    "\n",
    "### Ejercicio 2: Streaming con Filtros\n",
    "Implementa streaming que filtre o procese chunks específicos (ej: resaltar palabras clave).\n",
    "\n",
    "### Ejercicio 3: Chatbot Mejorado\n",
    "Extiende el chatbot con:\n",
    "- Historial de conversación\n",
    "- Comandos especiales (/help, /clear)\n",
    "- Diferentes personalidades\n",
    "\n",
    "## Conceptos Clave Aprendidos\n",
    "\n",
    "1. **Streaming** mejora la percepción de velocidad\n",
    "2. **Chunks** se procesan individualmente en tiempo real\n",
    "3. **UX** es significativamente mejor con streaming\n",
    "4. **Implementación** requiere manejo cuidadoso de generadores\n",
    "5. **Casos de uso** específicos donde streaming aporta valor\n",
    "\n",
    "## Próximos Pasos\n",
    "\n",
    "En el siguiente notebook exploraremos la **memoria en LangChain**, que nos permite mantener contexto entre múltiples interacciones del usuario."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
